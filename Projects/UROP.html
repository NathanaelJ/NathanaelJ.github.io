
<!DOCTYPE html>
<html lang="en">
        
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="../styles.css" />
        <title>Nathanael Jenkins | UROP</title>
        
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-PKWKKGM4TW"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-PKWKKGM4TW');
        </script>
    </head>


    <body>
        <script src="../../java.js"></script>
        <div w3-include-html="../../header.html"></div>
        <script>w3.includeHTML();</script>
        
        <main class="site-main">
            
            <!--    INTRO    -->
            <h1 class="wrapper">GPU Parallelisation of a 2D Navier-Stokes Solver</h1>
            <h2 class="wrapper">'Undergraduate Research Opportunity' at Imperial College London<br/><br/></h2>
            <p class="wrapper">Under the supervision of <a href="https://www.turbulencesimulation.com">Sylvain Laizet</a>, I completed a research project exploring parallelism in Computational Fluid Dynamics (CFD). The project evaluated the performance of a framework called <a href="https://github.com/illuhad/hipSYCL">hipSYCL</a>, which is designed to enable high-performance heterogeneous computing (this is a fancy way of saying 'using all of the hardware in a computer at once').<br/><br/>CFD programs are almost a perfect use-case for computational parallelism (that is, making lots of calculations simultaneously). Graphical Processing Units (GPUs) are designed for performing parallel calculations on images but this also makes them ideal for CFD simulations. In theory, running CFD simulations on GPUs could be much faster and more affordable than current approaches which generally use the Central Processing Unit (CPU).<br/></p>
            <picture>
                <img src="Proj4/Offloading.png" class="wrapper" alt="Offloading diagram">
            </picture>
            <figcaption class="wrapper">A (very) simplified overview of various kinds of computational parallelism</figcaption>
            <p class="wrapper"><br/>Heterogeneous parallelism takes advantage of GPUs, CPUs, and other hardware, making the most of all the available resources in a computer. These systems are typically more difficult to manage (note increasing numbers of arrows indicating increasing overhead), because separate hardware components must 'talk' to each other. The aim of this project was to explore the relatively new hipSYCL framework by using it to parallelise a 2D Navier-Stokes solver (a CFD program).<br/><br/>One major advantage of SYCL is that it uses single-source code to run on any device type. Exactly the same code can be compiled for use on a single CPU, GPU cluster, or heterogeneous system. This makes it easier to develop code which can be tested on any machine in confidence that the program could also be run on other architectures. Naturally, there are many limitations and nuances which must be managed, and this framework is still under development.<br/><br/></p>
            
            <!--    THE SOLVER    -->
            <hr width="50%" size="1px" color="#555" z-index="1">
            <h3 class="wrapper">The Solver</h3>
            <p class="wrapper">The primary project deliverable was a short finite-difference 2D Navier-Stokes solver used to simulate flow over a heat exchanger. Code was initially written in Fortran90, using a small computational domain of 129x129 elements. A sample of the solver result is shown below. The solver uses second-order differencing methods, with the Adams-Bashforth temporal scheme and periodic boundary conditions. The solver was 'translated' into C++ in order to test a SYCL implementation.<br/><br/></p>
            <picture>
                <source
                  srcset="Proj4/flow_Dark.gif" class="wrapper" alt="Flow gif">
                <img src="Proj4/flow_Dark.gif" style="width: 40vw; margin-left: auto; margin-right: auto;" alt="Flow gif">
            </picture>
            <figcaption class="wrapper">Simulated flow over a heat exchanger at Re=200 (coloured by periodicity)</figcaption>
            <p class="wrapper"><br/><br/></p>
            <picture>
                <img src="Proj4/comp.png" class="wrapper" alt="Comparison of Fortran and C++ functions">
            </picture>
            <figcaption class="wrapper">Example of original Fortran code against 'translated' C++ code</figcaption>
            <p><br/></p>

            <!--    PARALLELISATION    -->
            <hr width="50%" size="1px" color="#555" z-index="1">
            <h3 class="wrapper">SYCL</h3>
            <p class="wrapper">Several approaches to parallelisation using SYCL were explored, as discussed in the report below. The final SYCL implementation was thoroughly tested and found to perform at least 3.8x faster than the equivalent serial C++ code. The code can be run on a CPU, GPU, or FPGA without any changes and is made easy to compile using a short Makefile. Intel 'oneAPI' tools proved particularly useful when developing and testing the program.<br/><br/>Intel's' VTune profiler calculated that the program could theoretically experience a huge increase in speed of more than 300x when properly executed on a GPU. This agrees with simple calculations using Amdhal's Law, since it can be shown that nearly 99% of the program is parallelisable. It is only I/O tasks, including printing to screen and writing files, which cannot run from the GPU. However, inefficiencies in this implementation of SYCL combined with relatively new compilers made the actual speed increase much less impressive.<br/><br/>While SYCL makes high-performance computing on heterogeneous devices easier, it is still very difficult to perform 'true' heterogeneous computing where multiple hardware types are used in parallel. Because of SYCl's approach to queueing parallel tasks it is very difficult to use, for example, multiple GPUs and CPUs all in parallel for the same task at the same time. Instead, it is possible to run different tasks on each hardware device in tandem, although this is not ideal for CFD calculations. More testing data is available in the full report below.<br/><br/></p>

            <!--    REPORT    -->
            <hr width="50%" size="1px" color="#555" z-index="1">
            <h3 class="wrapper">Project Report</h3>
            <p class="wrapper"><a href="Proj4/UROP_Report.pdf" download>Click here to download a copy</a><br/><br/></p>
            <div class="iframewindow">
                <iframe class="iframepdf" src="Proj4/UROP_Report.pdf"></iframe>
            </div>
            <p class="wrapper"><br/>Please cite this project:<br/>Jenkins, N. (2021). <i>GPU Parallelisation of a 2D Navier-Stokes Solver</i> [pdf] London: Imperial College London. Available at: http://nathanaelj.github.io/Projects/UROP [Accessed: <script> document.write(new Date().toLocaleDateString()); </script>]<br/><br/></p>
            <p class="wrapper"><a href="../Projects.html">Check out more of my projects</a><br/><br/></p>
        </main>
        
        <script src="../../java.js"></script>
        <div w3-include-html="../../footer.html"></div>
        <script>w3.includeHTML();</script>
    </body>
    
</html>
